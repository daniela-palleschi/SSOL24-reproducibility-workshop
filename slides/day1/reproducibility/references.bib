@article{bochynska_reproducible_2023,
  title = {Reproducible Research Practices and Transparency across Linguistics},
  author = {Bochynska, Agata and Keeble, Liam and Halfacre, Caitlin and Casillas, Joseph V. and Champagne, Irys-Amélie and Chen, Kaidi and Röthlisberger, Melanie and Buchanan, Erin M. and Roettger, Timo B.},
  date = {2023-11-09},
  journaltitle = {Glossa Psycholinguistics},
  shortjournal = {Glossa Psycholinguistics},
  volume = {2},
  number = {1},
  issn = {2767-0279},
  doi = {10.5070/G6011239},
  url = {https://escholarship.org/uc/item/6m62j7p6},
  urldate = {2024-04-27},
  abstract = {Scientific studies of language span across many disciplines and provide evidence for social,\&nbsp; cultural, cognitive, technological, and biomedical studies of human nature and behavior. As it becomes increasingly empirical and quantitative, linguistics has been facing challenges and limitations of the scientific practices that pose barriers to reproducibility and replicability. One of the\&nbsp; proposed solutions to the widely acknowledged reproducibility and replicability crisis has been the implementation of transparency practices,\&nbsp; e.g., open access publishing, preregistrations, sharing study materials, data, and analyses, performing study replications, and declaring conflicts of interest. Here, we have assessed the prevalence of these practices in 600 randomly sampled journal articles from linguistics across two time points. In line with similar studies in other disciplines, we found that 35\% of the articles were published open access and the rates of sharing materials, data, and protocols were below 10\%. None of the articles reported preregistrations, 1\% reported replications, and 10\% had conflict of interest statements. These rates have not increased noticeably between 2008/2009 and 2018/2019, pointing to remaining barriers and the slow adoption of open and reproducible research practices in linguistics. To facilitate adoption of these practices, we provide a range of recommendations and solutions for implementing transparency and improving reproducibility of research in linguistics.},
  langid = {english},
  file = {/Users/danielapalleschi/Zotero/storage/PGLCZKLM/Bochynska et al. - 2023 - Reproducible research practices and transparency a.pdf}
}

@article{hardwicke_populating_2018,
  title = {Populating the {{Data Ark}}: {{An}} Attempt to Retrieve, Preserve, and Liberate Data from the Most Highly-Cited Psychology and Psychiatry Articles},
  shorttitle = {Populating the {{Data Ark}}},
  author = {Hardwicke, Tom E. and Ioannidis, John P. A.},
  editor = {Wicherts, Jelte M.},
  date = {2018-08-02},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {13},
  number = {8},
  pages = {e0201856},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0201856},
  url = {https://dx.plos.org/10.1371/journal.pone.0201856},
  urldate = {2024-04-27},
  langid = {english},
  file = {/Users/danielapalleschi/Zotero/storage/LG227N75/Hardwicke and Ioannidis - 2018 - Populating the Data Ark An attempt to retrieve, p.pdf}
}

@article{Knuth_literate_1984,
  title = {Literate Programming},
  author = {Knuth, Donald},
  date = {1984},
  journaltitle = {The computer journal},
  volume = {27},
  number = {2},
  pages = {97--111},
  file = {/Users/danielapalleschi/Zotero/storage/VE5KNQIB/270097.pdf}
}

@article{laurinavichyute_share_2022,
  title = {Share the Code, Not Just the Data: {{A}} Case Study of the Reproducibility of Articles Published in the {{Journal}} of {{Memory}} and {{Language}} under the Open Data Policy},
  author = {Laurinavichyute, Anna and Yadav, Himanshu and Vasishth, Shravan},
  date = {2022},
  journaltitle = {Journal of Memory and Language},
  volume = {125},
  pages = {12},
  abstract = {In 2019 the Journal of Memory and Language instituted an open data and code policy; this policy requires that, as a rule, code and data be released at the latest upon publication. How effective is this policy? We compared 59 papers published before, and 59 papers published after, the policy took effect. After the policy was in place, the rate of data sharing increased by more than 50\%. We further looked at whether papers published under the open data policy were reproducible, in the sense that the published results should be possible to regenerate given the data, and given the code, when code was provided. For 8 out of the 59 papers, data sets were inaccessible. The reproducibility rate ranged from 34\% to 56\%, depending on the reproducibility criteria. The strongest predictor of whether an attempt to reproduce would be successful is the presence of the analysis code: it increases the probability of reproducing reported results by almost 40\%. We propose two simple steps that can increase the reproducibility of published papers: share the analysis code, and attempt to reproduce one’s own analysis using only the shared materials.},
  langid = {english},
  file = {/Users/danielapalleschi/Zotero/storage/ISZ9VFQU/Laurinavichyute - 2022 - Share the code, not just the data A case study of.pdf}
}

@incollection{prinstein_open_2022,
  title = {An {{Open Science Workflow}} for {{More Credible}}, {{Rigorous Research}}},
  booktitle = {The {{Portable Mentor}}},
  author = {Corker, Katherine S.},
  editor = {Prinstein, Mitchell J.},
  date = {2022-07-31},
  edition = {3},
  pages = {197--216},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108903264.012},
  url = {https://www.cambridge.org/core/product/identifier/9781108903264%23CN-bp-11/type/book_part},
  urldate = {2024-04-29},
  isbn = {978-1-108-90326-4 978-1-108-84242-6 978-1-108-79438-1},
  langid = {english},
  file = {/Users/danielapalleschi/Zotero/storage/P8DK6X5E/Corker - 2022 - An Open Science Workflow for More Credible, Rigoro.pdf}
}
